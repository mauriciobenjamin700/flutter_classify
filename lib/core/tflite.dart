import 'package:flutter/services.dart';
import 'package:tflite_flutter/tflite_flutter.dart';
import '../schemas/result.dart';
import './image_handler.dart';

/// Classe respons√°vel pelo gerenciamento e execu√ß√£o de modelos TensorFlow Lite
/// para classifica√ß√£o de imagens.
///
/// Esta classe encapsula toda a l√≥gica necess√°ria para:
/// - Carregar modelos TFLite e arquivos de labels
/// - Executar infer√™ncia em imagens
/// - Processar e retornar resultados de classifica√ß√£o
class TFLiteHandler {
  /// Caminho para o arquivo do modelo TFLite
  final String modelPath;

  /// Caminho para o arquivo de labels/classes
  final String labelsPath;

  /// Inst√¢ncia do interpretador TensorFlow Lite
  Interpreter? _interpreter;

  /// Lista de labels/classes do modelo
  List<String>? _labels;

  /// Flag indicando se o modelo foi carregado com sucesso
  bool _isModelLoaded = false;

  /// Construtor da classe TFLiteHandler
  ///
  /// [modelPath] - Caminho para o arquivo .tflite do modelo
  /// [labelsPath] - Caminho para o arquivo .txt contendo os labels
  TFLiteHandler({required this.modelPath, required this.labelsPath});

  /// Carrega o modelo TensorFlow Lite e os arquivos de labels.
  ///
  /// Este m√©todo:
  /// - Verifica se o modelo j√° foi carregado para evitar recarregamento desnecess√°rio
  /// - Carrega o modelo TFLite dos assets
  /// - Carrega e processa o arquivo de labels
  /// - Exibe informa√ß√µes de debug sobre o modelo
  ///
  /// Throws [Exception] se houver falha no carregamento
  Future<void> loadModel() async {
    try {
      if (_isModelLoaded) {
        print('‚ö†Ô∏è Modelo j√° carregado. Reutilizando...');
        return;
      }

      _interpreter = await Interpreter.fromAsset(modelPath);

      if (_interpreter == null) {
        print('‚ùå Erro ao inicializar o interpretador');
        return;
      }

      print('‚úÖ Modelo carregado com sucesso');

      final labelsData = await rootBundle.loadString(labelsPath);
      _labels = labelsData
          .split('\n')
          .where((label) => label.isNotEmpty)
          .toList();

      _isModelLoaded = true;

      // Informa√ß√µes do modelo para debug
      final inputShape = _interpreter!.getInputTensor(0).shape;
      final outputShape = _interpreter!.getOutputTensor(0).shape;

      print('‚úÖ Modelo carregado com sucesso!');
      print('üì• Input shape: $inputShape');
      print('üì§ Output shape: $outputShape');
      print('üè∑Ô∏è Labels carregados: ${_labels!.length}');
    } catch (e) {
      print('‚ùå Erro ao carregar modelo: $e');
    }
  }

  /// Classifica uma imagem e retorna as probabilidades de cada classe.
  ///
  /// [imagePath] - Caminho para a imagem a ser classificada (asset ou arquivo local)
  ///
  /// Returns: Lista de probabilidades para cada classe (j√° normalizadas pelo modelo)
  /// Returns: Lista vazia em caso de erro
  ///
  /// Throws: Exception em caso de falha na classifica√ß√£o
  Future<List<double>> classifyImage(String imagePath) async {
    if (!_isModelLoaded) {
      await loadModel();
    }
    if (_interpreter == null) {
      print('‚ùå Erro: Interprete n√£o inicializado');
      return [];
    }

    try {
      final inputTensor = await ImageHandler.imageToTensor(
        imagePath,
        _interpreter!.getInputTensor(0).shape[2],
        _interpreter!.getInputTensor(0).shape[1],
      );

      final outputShape = _interpreter!.getOutputTensor(0).shape;
      final output = List.generate(
        outputShape[0],
        (index) => List<double>.filled(outputShape[1], 0.0),
      );

      _interpreter!.run(inputTensor, output);

      // ‚úÖ Usa valores diretos (modelo j√° aplica softmax)
      final probabilities = output[0];

      // üé® Log formatado com 2 casas decimais
      final formattedProbs = probabilities
          .map((prob) => '${(prob * 100).toStringAsFixed(2)}%')
          .toList();

      print('üéØ Probabilidades: $formattedProbs');
      return probabilities;
    } catch (e) {
      print('‚ùå Erro ao classificar imagem: $e');
      return [];
    }
  }

  /// Classifica uma imagem e retorna o resultado completo com label e confian√ßa.
  ///
  /// Este m√©todo combina a classifica√ß√£o com o processamento dos resultados,
  /// retornando a classe mais prov√°vel junto com sua confian√ßa.
  ///
  /// [imagePath] - Caminho para a imagem a ser classificada
  ///
  /// Returns: [PredictionResult] contendo ID, label e confian√ßa da predi√ß√£o
  /// Returns: Resultado com "Desconhecido" em caso de erro
  Future<PredictionResult> classifyImageWithLabels(String imagePath) async {
    final probabilities = await classifyImage(imagePath);

    // Encontra a classe com maior probabilidade
    double maxProb = 0.0;
    int maxIndex = 0;

    for (int i = 0; i < probabilities.length; i++) {
      if (probabilities[i] > maxProb) {
        maxProb = probabilities[i];
        maxIndex = i;
      }
    }

    final label = _labels != null && maxIndex < _labels!.length
        ? _labels![maxIndex]
        : 'Desconhecido';

    return PredictionResult(id: maxIndex, label: label, confidence: maxProb);
  }

  /// Retorna informa√ß√µes detalhadas sobre o modelo carregado.
  ///
  /// Inclui informa√ß√µes como:
  /// - Dimens√µes de entrada e sa√≠da do modelo
  /// - N√∫mero de labels/classes
  /// - Lista completa de labels
  ///
  /// Returns: Map com informa√ß√µes do modelo ou erro se n√£o inicializado
  Map<String, dynamic> getModelInfo() {
    if (!_isModelLoaded) {
      return {'error': 'Modelo n√£o inicializado'};
    }

    final inputShape = _interpreter!.getInputTensor(0).shape;
    final outputShape = _interpreter!.getOutputTensor(0).shape;

    return {
      'input_shape': inputShape,
      'output_shape': outputShape,
      'labels_count': _labels?.length ?? 0,
      'labels': _labels,
    };
  }

  /// Libera todos os recursos utilizados pelo interpretador TensorFlow Lite.
  ///
  /// Este m√©todo deve ser chamado quando o classificador n√£o for mais utilizado
  /// para evitar vazamentos de mem√≥ria. Ap√≥s chamar este m√©todo, √© necess√°rio
  /// recarregar o modelo para utiliz√°-lo novamente.
  ///
  /// Limpa:
  /// - Inst√¢ncia do interpretador
  /// - Lista de labels
  /// - Flag de modelo carregado
  void dispose() {
    _interpreter?.close();
    _interpreter = null;
    _labels = null;
    _isModelLoaded = false;
    print('üßπ Recursos do TFLite liberados');
  }
}
